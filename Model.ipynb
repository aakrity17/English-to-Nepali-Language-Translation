{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokens = load(open('./en_tokens.pkl', 'rb'))\n",
    "np_tokens = load(open('./np_tokens.pkl', 'rb'))\n",
    "\n",
    "# sorted() can only be used with iterable data structure\n",
    "# So, here we are converting set() type to list() type\n",
    "encoder_tokens = sorted(list(en_tokens))\n",
    "decoder_tokens = sorted(list(np_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of Nepali/Decoder tokens is: 186399\n",
      "The length of English/Encoder tokens is: 64316\n"
     ]
    }
   ],
   "source": [
    "# Here we are translating from English to Nepali language\n",
    "# So, en_tokens act as encoder tokens and np_tokens act as decoder tokens\n",
    "num_decoder_tokens = len(decoder_tokens)\n",
    "num_encoder_tokens = len(encoder_tokens)\n",
    "\n",
    "print(\"The length of Nepali/Decoder tokens is:\", num_decoder_tokens)\n",
    "print(\"The length of English/Encoder tokens is:\", num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of Nepali/Decoder tokens is: 186400\n",
      "The length of English/Encoder tokens is: 64316\n"
     ]
    }
   ],
   "source": [
    "# For zero padding\n",
    "num_decoder_tokens += 1\n",
    "\n",
    "print(\"The length of Nepali/Decoder tokens is:\", num_decoder_tokens)\n",
    "print(\"The length of English/Encoder tokens is:\", num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Vocabulary of the words\n",
    "encoder_token_dict = dict([(word, i+1) for i, word in enumerate(encoder_tokens)])\n",
    "decoder_token_dict = dict([(word, i+1) for i, word in enumerate(decoder_tokens)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Splitting of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nepali</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>START_TOKEN “मानौ एउटी स्त्रीसँग दशवटा चाँदीका...</td>\n",
       "      <td>or what woman if she had ten drachma coins if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>START_TOKEN ती दुष्ट मानिसहरू हिंस्रक सिंहहरू ...</td>\n",
       "      <td>he is like a lion that is greedy of his prey a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>START_TOKEN प्रक्रिया दृश्य क्रम स्तम्भ END_TOKEN</td>\n",
       "      <td>process view sort column</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>START_TOKEN जहा ट्याबहरु देखाइन सकिन्थ्यो वा स...</td>\n",
       "      <td>whether tooltips should be shown on widgets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>START_TOKEN अनुष्ठान अनुसार जहां केटि र महिलाह...</td>\n",
       "      <td>ritual servitude where girls and women are ple...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Nepali  \\\n",
       "0  START_TOKEN “मानौ एउटी स्त्रीसँग दशवटा चाँदीका...   \n",
       "1  START_TOKEN ती दुष्ट मानिसहरू हिंस्रक सिंहहरू ...   \n",
       "2  START_TOKEN प्रक्रिया दृश्य क्रम स्तम्भ END_TOKEN   \n",
       "3  START_TOKEN जहा ट्याबहरु देखाइन सकिन्थ्यो वा स...   \n",
       "4  START_TOKEN अनुष्ठान अनुसार जहां केटि र महिलाह...   \n",
       "\n",
       "                                             English  \n",
       "0  or what woman if she had ten drachma coins if ...  \n",
       "1  he is like a lion that is greedy of his prey a...  \n",
       "2                           process view sort column  \n",
       "3        whether tooltips should be shown on widgets  \n",
       "4  ritual servitude where girls and women are ple...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./cleaned_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data is: (144216,) (144216,)\n",
      "The shape of the trest data is: (16025,) (16025,)\n"
     ]
    }
   ],
   "source": [
    "x = data[\"English\"]\n",
    "y = data[\"Nepali\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state=42)\n",
    "\n",
    "print(\"The shape of the training data is:\", x_train.shape, y_train.shape)\n",
    "print(\"The shape of the trest data is:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding/Mapping Text to Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of words in one single Nepali sentence throughout the corpus is: 388\n",
      "The maximum number of words in one single English sentence throughout the corpus is: 498\n"
     ]
    }
   ],
   "source": [
    "np_words_count = data[\"Nepali\"].apply(lambda x:len(str(x).split()))\n",
    "en_words_count = data[\"English\"].apply(lambda x:len(str(x).split()))\n",
    "\n",
    "np_sentence_max_length = max(np_words_count)\n",
    "en_sentence_max_length = max(en_words_count)\n",
    "\n",
    "print(\"The maximum number of words in one single Nepali sentence throughout the corpus is:\", np_sentence_max_length)\n",
    "print(\"The maximum number of words in one single English sentence throughout the corpus is:\", en_sentence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128341\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(np_words_count):\n",
    "    if j == np_sentence_max_length:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128341\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(en_words_count):\n",
    "    if j == en_sentence_max_length:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fall on the enemy dig below the gap on the right then quickly go right over his head pick up the gold fall through a false brick run up the ladder to the right and go to the right along the lower pole dig to the right which traps the second enemy get the gold fall dig left fall collect two gold pieces and go up two ladders move to the left via a false brick the second enemy should still be trapped below go left to the ladder down then left and down through a false brick collect one gold dig on the right get three gold dig and go up all the ladders on the right go left on the pole again but this time climb upwards get one gold and dig right to trap another enemy move up to the top go right fall and continue to the concrete area at top center outwit the enemy in the concrete area then exit by falling on him and moving to the gap on the left and down through two false bricks hold onto the pole at center screen go right and back on up to the top move left on the pole and wait for the other enemy to enter the concrete area pick up the top gold fall and exit left again leaving two enemies trapped in the concrete go back up to the top again but this time continue left towards the topleft corner of the screen when you get up there dig fall through onto some gold and dig left twice while falling further now fall down the leftmost shaft and dig the brick that blocks the shaft wait for the enemy below to step into the shaft then fall on him in order to collect the gold encased in concrete drop onto the remaining gold and fall to the bottomleft corner run right and up right again fall on three gold pieces and move on to the midbottom section outwit the enemy go to the topmost ladder on the right dig twice and fall through one gold and three bricks while digging right exit right to get more gold then climb the ladder dig and fall to collect another two gold pieces climb the ladder again take the pole left go up and then right to claim four gold pieces dig at the righthand end and fall through three false bricks fall into the chamber going right and digging left dig on the lower left to get out then go back up to the pole and fall to onto the gold in this chamber exit right this time collect some gold and climb up up up outwit the enemies in the upperright area it is possible to lure them into the chamber below by running ahead of them up the ladders collect the rightmost midlevel gold second to last and the gold at the bottom right last of all get out quick\n"
     ]
    }
   ],
   "source": [
    "print(data[\"English\"][128341])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN शत्रु माथि झर्नुहोस् दायाँको खाली स्थान तल खन्नुहोस् त्यसपछि उसको टाउको माथिदायाँ तिर छिटो दायाँ जानुहोस् सुन टिप्नुहोस् झुक्याउने इट्टाबाट झर्नुहोस् दायाँको भर्याङको माथि दगुर्नुहोस् र तल्लो पोलको दायाँ जानुहोस् दायाँ तिर खन्नुहोस् जसले दोस्रो शत्रुलाई जालमा पर्दछ सुन प्राप्त गर्नुहोस् झर्नुहोस् बायाँ खन्नुहोस् झर्नुहोस् दुइ सुनका टुक्रा सङ्कलन गर्नुहोस् र दुइ भर्याङ माथि जानुहोस् झुक्याउने इट्टा हुँदै बायाँ जानुहोस् दोस्रो शत्रु तल जालमा रहिरहेको हुनुपर्दछ भर्याङको बायाँ तल जानुहोस् त्यसपछि झुक्याउने इट्टा हुँदै बायाँ र तल जानुहोस् एउटा सुन सङ्कलन गर्नुहोस् दायाँ खन्नुहोस् तीनवटा सुन लिनुहोस् खन्नुहोस् र दायाँका सबै भर्याङ माथि जानुहोस् पोलको बायाँ फेरि जानुहोस् तर यस पाली माथ तिर उक्लनुहोस् एउटा सुन लिनुहोस् र अर्को शत्रुलाई जालमा पार्न दायाँ खन्नुहोस् माथि तिर जानुहोस् दायाँ जानुहोस् झर्नुहोस् र माथि बीचको ढलान क्षेत्रमा गइराख्नुहोस् ढलान क्षेत्रमा शत्रुलाई झुक्याउनुहोस् त्यसपछि उसमाथि झर्नुहोस् र दुइ झुक्याउने इट्टाबाट बायाँ तलको खाली स्थानमा गएर बाहिरिनुहोस् पर्दा बीचको पोलमा अडिनुहोस् दायाँ जानुहोस् दायाँ जानुहोस् र पछाडि तिरको माथि जानुहोस् ढलान क्षेत्रमा प्रवेश गर्न पोलको बायाँ जानुहोस् र अन्य शत्रुलाई प्रतिक्षा गर्नुहोस् ढलानमा जालमा परेका दुइ शत्रुलाई छोडेर माथिको सुनको टिप्नुहोस् झर्नुहोस् र फेरि बायाँ बाहिरिनुहोस् फेरि माथि फर्कनुहोस् तर यस पटक पर्दाको माथिल्लो बायाँ कुना तिर गरइराख्नुहोस् तपाईँ त्यहाँ पुगेपछि खन्नुहोस् त्यसबाट सुनका टुक्रमा माथि झर्नुहोस् र अगाडि झर्दै गर्दा दुइ पटक बायाँ खन्नुहोस् सबैभन्दा बायाँको डण्डीमा झर्नुहोस् र डण्डीलाई रोकेको इट्टालाई खन्नुहोस् डण्डीमा अगाडि बढ्न शत्रुलाई तल प्रतिक्षा गर्नुहोस् त्यसपछि ढलान भित्रको सुन सङ्कलन गर्न उ माथि झर्नुहोस् बाँकी सुनमाथि झर्नुहोस् र तलको बायाँ कुनामा झर्नुहोस् दायाँ र माथि फेरी दायाँ दगुर्नुहोस् तीनवटा सुनका टुक्रा माथि झर्नुहोस् र तलको बीच खण्डमा झर्नुहोस् शत्रुलाई झुक्याउनुहोस् दायाँको सबैभन्दा माथिल्लो भर्याङमा जानुहोस् दुइ पटक खन्नुहोस् र दायाँ खन्दै गर्दा एउटा सुन र तीनवटा इट्टाबाट झर्नुहोस् अरु सुन प्राप्त गर्न दायाँ बाहिरिनुहोस् त्यसपछि भर्याङ उक्लनुहोस् अन्य दुइ टुक्रा सुन सङ्कलन गर्न खन्नुहोस् र झर्नुहोस् भर्याङ फेरि उक्लनुहोस् बायाँको पोलमा जानुहोस् चारवटा सुनका टुक्रमा लिनका लागि माथि र त्यसपछि दायाँ जानुहोस् दायाँतिरको अन्त्यमा खन्नुहोस् र तीनवाट झुक्याउने इट्टाबाट झर्नुहोस् दायाँ जाँदै र बायाँ खन्दै च्याम्बरमा झर्नुहोस् बाहिरिनका लागि तलको बायाँ तिर खन्नुहोस् त्यसपछि पोलमा फर्नुहोस् र यो कोठाका ससुनमाथि झर्नुहोस् यसपाली दायाँ बाहिरनुहोस् केही सुन सङ्कलन गर्नुहोस् र माथि माथि माथि उक्लनुहोस् दायाँको माथिल्लो क्षेत्रमा शत्रुलाई झुक्याउनुहोस् भर्याङको माथितिर शत्रुको अगाडि दगुरेर तिनीहरूलाई च्याम्बरमा लोभ्याउन सम्भव हुन्छ सबैभन्दा दायाँको अन्तिमबाट दोस्रो मध्यम स्तरको र सबैभन्दा तलको दायाँ बटनको सुन सङ्कलन गर्नुहोस् चाँडै बाहिरिनुहोस् END_TOKEN\n"
     ]
    }
   ],
   "source": [
    "print(data[\"Nepali\"][128341])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(x, y, batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            encoder_input_vec = np.zeros((batch_size, en_sentence_max_length), dtype='float32')\n",
    "            decoder_input_vec = np.zeros((batch_size, np_sentence_max_length), dtype='float32')\n",
    "            decoder_target_vec = np.zeros((batch_size, np_sentence_max_length, num_decoder_tokens), dtype='float32')\n",
    "            \n",
    "            for j, (input_text, target_text) in enumerate(zip(x[i:i+batch_size], y[i:i+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    # Encoder input sequence\n",
    "                    encoder_input_vec[j, t] = encoder_token_dict[word]\n",
    "                    for t, word in enumerate(target_text.split()):\n",
    "                        if t < len(target_text.split())-1:\n",
    "                            # Decoder input sequence\n",
    "                            decoder_input_vec[j, t] = decoder_token_dict[word]\n",
    "                        elif t > 0:\n",
    "                            # decoder target sequence (one hot encoded)\n",
    "                            # does not include the START_ token\n",
    "                            # Offset by one timestep\n",
    "                            decoder_target_vec[j, t-1, decoder_token_dict[word]] = 1.\n",
    "            yield([encoder_input_vec, decoder_input_vec], decoder_target_vec)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedded = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedded)\n",
    "# We discard `encoder_outputs` and only keep the states\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the decoder, using encoder_states as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)\n",
    "decoder_embedded = decoder_embedding_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, state_dh, state_dc = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn encoder_input data & decoder_input_vec into decoder_target_vec\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    16464896    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    47718400    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 525312      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 186400) 47904800    lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 113,138,720\n",
      "Trainable params: 113,138,720\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(x_train)\n",
    "val_samples = len(x_test)\n",
    "batch_size = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-c88eceb372ad>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "  106/14421 [..............................] - ETA: 37:52:35 - loss: 0.0041"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c88eceb372ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_samples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./Models/model_{i}.h5\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    generator = generate_batch(x_train, y_train, batch_size=batch_size)\n",
    "    model.fit_generator(generator=generator,\n",
    "                    steps_per_epoch=train_samples//batch_size,\n",
    "                    epochs=1,\n",
    "                    validation_data=generate_batch(x_test, y_test, batch_size=batch_size),\n",
    "                    validation_steps=val_samples//batch_size,\n",
    "                    verbose=1)\n",
    "    model.save(f\"./Models/model_{i}.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
